{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/pavankumarkotapally/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/pavankumarkotapally/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>aisle_id</th>\n",
       "      <th>department_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Chocolate Sandwich Cookies</td>\n",
       "      <td>61</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>All-Seasons Salt</td>\n",
       "      <td>104</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Robust Golden Unsweetened Oolong Tea</td>\n",
       "      <td>94</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Smart Ones Classic Favorites Mini Rigatoni Wit...</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Green Chile Anytime Sauce</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id                                       product_name  aisle_id  \\\n",
       "0           1                         Chocolate Sandwich Cookies        61   \n",
       "1           2                                   All-Seasons Salt       104   \n",
       "2           3               Robust Golden Unsweetened Oolong Tea        94   \n",
       "3           4  Smart Ones Classic Favorites Mini Rigatoni Wit...        38   \n",
       "4           5                          Green Chile Anytime Sauce         5   \n",
       "\n",
       "   department_id  \n",
       "0             19  \n",
       "1             13  \n",
       "2              7  \n",
       "3              1  \n",
       "4             13  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"products.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    # Lemmatize text\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Apply the cleaning function to the product_name column\n",
    "df['cleaned_product_name'] = df['product_name'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ice Cream: 1.0\n",
      "Ice Cream Cake Ice Cream: 0.920664999193916\n",
      "Ice Cream, Chocolate: 0.8700409168179906\n",
      "Chocolate Ice Cream: 0.8700409168179906\n",
      "Ice Cream Chocolate: 0.8700409168179906\n",
      "Sweet Cream Ice Cream: 0.8542200890467642\n",
      "Ice Cream Bars: 0.8441625691704493\n",
      "Cookies N Cream Ice Cream: 0.8425304712725254\n",
      "Cookies 'N Cream Ice Cream: 0.8425304712725254\n",
      "Ice Cream, Cookies & Cream: 0.8425304712725254\n"
     ]
    }
   ],
   "source": [
    "def find_similar_products(input_product_name, df, top_n=10):\n",
    "    # Clean the input product name\n",
    "    cleaned_input = clean_text(input_product_name)  # Use your defined clean_text function\n",
    "\n",
    "    # Create a DataFrame for the cleaned input to concatenate with the original df\n",
    "    input_df = pd.DataFrame({'cleaned_product_name': [cleaned_input]})\n",
    "\n",
    "    # Use pd.concat to combine the original df with the new input_df\n",
    "    temp_df = pd.concat([df, input_df], ignore_index=True)\n",
    "\n",
    "    # Proceed with your TF-IDF vectorization and cosine similarity calculation\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(temp_df['cleaned_product_name'])\n",
    "    \n",
    "    # Calculate cosine similarity with the last item (input product)\n",
    "    cosine_sim = cosine_similarity(tfidf_matrix[-1:], tfidf_matrix[:-1])\n",
    "    \n",
    "    # Get the indices of the top N similar products\n",
    "    indices = cosine_sim.argsort()[0][-top_n:][::-1]\n",
    "    \n",
    "    # Return the top N similar products' names and their similarity scores\n",
    "    similar_products = df.iloc[indices]\n",
    "    similar_products_scores = cosine_sim[0][indices]\n",
    "    \n",
    "    return similar_products['product_name'], similar_products_scores\n",
    "\n",
    "# Example usage\n",
    "input_product_name = \"Ice Cream\"\n",
    "similar_products, scores = find_similar_products(input_product_name, df, 10)\n",
    "for product, score in zip(similar_products, scores):\n",
    "    print(f\"{product}: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: python-Levenshtein in /Users/pavankumarkotapally/Library/Python/3.9/lib/python/site-packages (0.25.0)\n",
      "Requirement already satisfied: Levenshtein==0.25.0 in /Users/pavankumarkotapally/Library/Python/3.9/lib/python/site-packages (from python-Levenshtein) (0.25.0)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=3.1.0 in /Users/pavankumarkotapally/Library/Python/3.9/lib/python/site-packages (from Levenshtein==0.25.0->python-Levenshtein) (3.6.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-Levenshtein\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import process\n",
    "import pandas as pd\n",
    "def find_similar_products(input_product_name, df, top_n=10):\n",
    "    # Extract product names to a list\n",
    "    product_names = df['product_name'].tolist()\n",
    "    \n",
    "    # Use fuzzywuzzy's process to find matches\n",
    "    results = process.extract(input_product_name, product_names, limit=top_n)\n",
    "    \n",
    "    # Convert results to DataFrame for nicer output and potentially further processing\n",
    "    similar_products_df = pd.DataFrame(results, columns=['Product Name', 'Similarity Score'])\n",
    "    \n",
    "    return similar_products_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        Product Name  Similarity Score\n",
      "0                                       Basmati Rice               100\n",
      "1                                  Aged Basmati Rice                95\n",
      "2           Chicken Curry with Seasoned Basmati Rice                90\n",
      "3  World Cuisine Certified Halal Chicken Tikka Ma...                90\n",
      "4                         Organic White Basmati Rice                90\n",
      "5  Chicken Tikka Masala with Cumin Infused Basmat...                90\n",
      "6                 Chicken Vindaloo with Basmati Rice                90\n",
      "7                                Smoked Basmati Rice                90\n",
      "8            Peas Pulav Basmati Rice With Green Peas                90\n",
      "9              Organic California White Basmati Rice                90\n"
     ]
    }
   ],
   "source": [
    "input_product_name = \"basmati rice\"\n",
    "similar_products_df = find_similar_products(input_product_name, df, 10)\n",
    "print(similar_products_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'OPENAPIKEY'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/pavankumarkotapally/Downloads/quickpantry/Similarity.ipynb Cell 9\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pavankumarkotapally/Downloads/quickpantry/Similarity.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/pavankumarkotapally/Downloads/quickpantry/Similarity.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(os\u001b[39m.\u001b[39;49menviron[\u001b[39m'\u001b[39;49m\u001b[39mOPENAPIKEY\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/os.py:679\u001b[0m, in \u001b[0;36m_Environ.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    676\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencodekey(key)]\n\u001b[1;32m    677\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[1;32m    678\u001b[0m     \u001b[39m# raise KeyError with the original key value\u001b[39;00m\n\u001b[0;32m--> 679\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    680\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecodevalue(value)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'OPENAPIKEY'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(os.environ['OPENAPIKEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
